---
title: "Data Wrangling (1)"
author: "Haohan Chen"
date: "Last update: `r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document: default
  pdf_document: default
  md_document: default
knit: (function(inputFile, encoding){rmarkdown::render(inputFile, encoding = encoding, output_format = "all", knit_root_dir = getwd())})
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives of this Lecture

This lecture introduces data wrangling with R. Using V-Dem data as an example, we will learn how to use the wrangle data with a set of [`tidyverse`](https://www.tidyverse.org/) functionality. Specifically, we will focus on functions...

1.  to import and export data: `read_csv` , `write_csv` (with a brief introduction to other data import/ export functions from [`readr`](https://readr.tidyverse.org/)).

2.  to take a subset of *columns* in the existing data: `select`

3.  to rename columns: `rename`

4.  to take a subset of *rows* by some simple conditions: `slice_`

5.  to take a subset of *rows* by some more complicated conditions: `filter`

6.  to sort the rows based on the value of one or multiple columns: `arrange`

7.  to perform (4) (5) (6) group by group: `group_by`, `ungroup`

8.  to create new columns in the data: `group_by`, `mutate`, `ungroup`

9.  to summarize the data: `group_by`, `summarise`, `ungroup`

## Outline of In-Class Demo

To demonstrate the above functionality, we will use real-world political data from [V-Dem](https://v-dem.net/). Specifically, we will use the above function to explore the state of global economic development from 1984 to 2022. Our effort will take the following step (with one-on-one mappings with the above tools).

1.  Read a part of pre-processed V-Dem data into R: 1984-2022 "external" data in the V-Dem dataset.
2.  Consulting the dataset's [codebook](https://github.com/haohanchen/HKU_POLI3148_23Fall/blob/main/_DataPublic_/vdem/documentation/codebook_v13.pdf) and take a **subset** of indicators of *economic development* (along with country-year identifiers).
    -   *See a list of country-yer identifiers on p. 5 of the codebook (under "1.7 Identifier Variables in the V-Dem Datasets").*

    -   *See a list of development indicators on p. 23 of the codebook (under "9. Background Factors").*
3.  Rename the column to name their names informative to readers.
4.  Find the country-year with the *highest* and *lowest* level of economic development. In addition, create a dataset containing a random sample of country-year in the dataset.
5.  Create a dataset focusing on the economic development of Asian countries and regions; Create a dataset that contains only countries/ regions whose development level pass certain threshold.
6.  Create a dataset whose rows are sorted by the development level of country-year.
7.  Create a dataset that contains the year of the higest development level for each country/ region respectively.
8.  Add the following economic indicators to the data:
    1.  Country-year development level with reference to that of 1984.

    2.  Year-on-year economic growth.
9.  Perform a data availability/ integrity check. Then aggregate the data into a new country-level dataset which contains the following indicators:
    1.  Average development level from 1984 to 2022.

    2.  Magnitude of growth from 1984 to 2022.

## In-Class Exercise

The quality of education has a decisive effect on a country's future development. Applying the data wrangling tools we introduce in this lecture, perform the following task:

1.  **Coodbook lookup**. Look up the codebook, answer the following questions:
    1.  What indicators regarding the quality of education are available in the V-Dem datasets?

    2.  What are the data's coverage (i.e., for which countries and years do we have data?)

    3.  What are their sources? Provide the link to least 1 source.
2.  **Subset by columns**
    1.  Create a dataset containing only the country-year identifiers and indicators of education quality.

    2.  Rename the columns of education quality to make them informative.
3.  **Subset by rows**
    1.  List 5 countries-years that have the highest education level among its population.

    2.  List 5 countries-years that suffer from the most severe inequality in education.
4.  **Summarize the data**
    1.  Check data availability: For which countries and years are the indicators of education quality available?

    2.  Create two types of country-level indicators of education quality

        1.  Average level of education quality from 1984 to 2022

        2.  Change of education quality from 1984 to 2022

    3.  Examine the data and *briefly* discuss: Which countries perform the best and the worst in terms of education quality in the past four decades?

**Submission requirement:** You will submit your outputs through Moodle. In your submission:

1.  Attach a PDF document rendered by Rmarkdown
2.  In the text field of your submission, include the link to the corresponding Rmarkdown file in your *DaSPPA portfolio* GitHub repo.

**Due:** October 6, 2023

*Note:* *Please* *only use the functions we cover in this lecture for this exercise. There is [absolutely no need]{.underline} to perform any data visualization for this exercise... We will get there in later lectures.*

## Further reading

-   R for Data Science (2e) Chapters 4, 5, 8: <https://r4ds.hadley.nz/>

-   `readr` documentation (note: read the "cheatsheet"): <https://readr.tidyverse.org/>

-   `dplyr` documentation (note: read the "cheatsheet"): <https://dplyr.tidyverse.org/>

-   V-Dem documentation: <https://v-dem.net/>

## Demo

### 0. Load the `tidyverse` Packages

This section loads the packages we need in this lecture.

```{r}
library(tidyverse)
```

### 1. Import and Export the V-Dem Data

This section loads the VDEM dataset and describe its basic information

```{r}
d <- read_csv("data/vdem/1984_2022/vdem_1984_2022_external.csv")
```

### 2. Select economic development indicators

We start by examining the dataset. `name()` is almost always the first function I apply to a dataset. It gives us the names of all the columns

```{r}
names(d)
```

We may use some alternative functions that provides information about the dataset. The `str()` provides not only variable names, but also their data types and a few example data points.

```{r}
# Warning: If you have many variables, the output of str() will be lengthy!
str(d)
```

Usually, the second step of my data inquiry is having an overview of the *identifiers* of data points. In our case, the identifiers are country names, country IDs, and years. Using the `distinct()` function can effectively identify the distinct levels of *identifiers*

```{r}
d |> select(country_name, country_id, year) |> distinct()
```

```{r}
# Which countries are in this dataset
d |> select(country_name) |> distinct()
```

```{r}
d |> select(year) |> distinct()
```

Select both the country identifiers, GDP, and GDP per capita.

```{r}
d_gdp <- d |> 
  select(country_name, country_id, year, e_gdp, e_gdppc)

d_gdp
```

### 3. Rename Columns to Make Names Informative

```{r}
d_gdp <- d_gdp |>
  rename("GDP" = "e_gdp", "GDP_per_capita" = "e_gdppc",
         "Country" = "country_name", "ID" = "country_id",
         "Year" = "year")

d_gdp
```

### 4. Subset Rows of the Data Using `slice_`

The set of `slice_` functions will become handy when you want to take a subset of rows based on some simple rules.

If you would like to get 10 obervations (countries-years) with the maximum `GDP`, use `slice_max`:

```{r}
# Want countries-years with highest GDP
d_gdp |> slice_max(order_by = GDP, n = 10)
```

Similiarily, if you want a subset of countries-years with mimnimal GDP, use `slice_min`:

```{r}
# Get countries-years with the lowest GDP
d_gdp |> slice_min(order_by = GDP, n = 10)
```

Finally, if you wish to take a random sample of observations in the data, use `slice_sample`. Note that you may tell R the exact sample size you want:

```{r}
set.seed(52)
d_gdp |> slice_sample(n = 10) # Sample 10 observations
```

Or you may define the sample size as a poroportion of the original data size:

```{r}
set.seed(52)
d_gdp |> slice_sample(prop = 0.1)
```

The `set.seed` function specify a random seed with which the system uses to generate the "random sample." Long story short, "random" stuff generated by a machine are never really random. Instead, the random outputs (in our case, a random subset of the data) are results of the computer input some "random seed" to some complicated formula. When you define a random seed, you can guarantee that you obtain the same random sample every time you run the program -- this makes your data science research reproducible. As we have discussed, reproducibility is a desired feature of a data science project. So I would strongly recommend setting a random seed every time.

### 5. Subset Rows of the Data Using `filter`

For example, we may take the observations whose `Year` variable ranges from 2000 to 2005.

```{r}
# Want: 2000-2005 data
d_gdp |> filter(Year >= 2000 & Year <= 2005)
```

We may subset observations whose `Country` variable, a `character` variable, equals to the text `"China"`.

```{r}
d_gdp |> filter(Country == "China")
```

We may also stack multiple `filter` functions. For example, you may do the following if you want to look at a subset of the data whose `Year` ranges from 2000 to 2005 and `Country` equals to `"China"`:

```{r}
# Want: 2000 - 2005 from China
d_gdp |> 
  filter(Year >= 2000 & Year <= 2005) |> 
  filter(Country == "China")
```

### 6. Sort the Data based on Values of Rows using `arrange`

Now we will try to sort the dataset `d_gdp` by the value of GDP per capita using the `arrange`. We may have country-year with small values of `GDP_per_capita` appearing first and those with larger values of `GDP_per_capita` coming after them.

```{r}
# Want: sort the row by GDP per capita
d_gdp |> arrange(GDP_per_capita)
```

Want the countries-years with larger values of `GDP_per_capita` appear first? Simply reverse the value using `-GDP_per_capita`. Alternatively, you may replace `desc(GDP_per_capita)`.

```{r}
d_gdp |> arrange(-GDP_per_capita)
```

### 7. Perform (4) (5) (6) group by group: `group_by`, `ungroup`

**Task:** Create a dataset that contains the year of the higest development level for each country/ region respectively.

1.  Perform a data availability/ integrity check. Then aggregate the data into a new country-level dataset which contains the following indicators:
    1.  Average development level from 1984 to 2022.

    2.  Magnitude of growth from 1984 to 2022.

```{r}
# the year where countries have highest GDP
d_gdp |>
  group_by(Country) |>
  slice_max(GDP, n = 1)

# group_by itself does nothing to the dataset, only making them into smaller groups
# what's important is what's after group_by
```

```{r}
# how many entries are there for each country
d_gdp |>
  group_by(Country) |>
  count()
```

```{r}
# year when countries have worst GDP
d_gdp |>
  group_by(Country) |>
  slice_min(order_by = GDP, n = 1)
```

### 8. Create new columns in the data: `group_by`, `mutate`, `ungroup`

**Task:** Add the following economic indicators to the data:

1.  Country-year development level with reference to that of 1984.

2.  Year-on-year economic growth.

```{r}

# GDP relative to the average GDP in the world
d_gdp |>
  mutate(GDP_over_avg = GDP / mean(GDP, na.rm = TRUE))

# country-year development level w/ ref avg
d_gdp |>
  group_by(Country) |>
  select(Year, GDP) |>
  mutate(GDP_over_avg = GDP / mean(GDP, na.rm = TRUE))

# country-year development level w/ ref to 1984: first()
d_gdp |>
  group_by(Country) |>
  arrange(Year) |>
  mutate(GDP_ref_84 = GDP / first(GDP)) |>
  ungroup() |>
  # after defining new column,
  # no need to maintain the group
  # if keep grouping, then all 1984 will appear at beginning
  arrange(Country, Year)

# year-on-year econ growth: lag()
d_gdp |>
  group_by(Country) |>
  arrange(Year) |>
  mutate(gdp_year_change = GDP - lag(GDP, n = 1)) |>
  ungroup() |>
  select(Country, Year, gdp_year_change) |>
  arrange(Country)

```

`mutate()` does not change the number of rows; it only changes columns.

### 9. Summarize the data: `group_by`, `summarise`, `ungroup`

**Task:** Perform a data availability/ integrity check. Then aggregate the data into a new country-level dataset which contains the following indicators:

1.  Average development level from 1984 to 2022.

2.  Magnitude of growth from 1984 to 2022.

```{r}

d_gdp |>
  group_by(Country) |>
  summarize(gdp_avg = mean(GDP, na.rm = TRUE),
            gdppc_avg = mean(GDP_per_capita, na.rm = TRUE))

d_gdp |>
  filter(Year >= 1984 & Year <= 2019) |>
  group_by(Country) |>
  arrange(Year) |>
  summarise(gdp_growth = last(GDP) - first(GDP)) |>
  ungroup() |>
  arrange(Country)

# see how many data missing for each country (data integrity check)
d_gdp |>
  mutate(gdp_missing = as.numeric(is.na(GDP))) |>
  # as numeric: TRUE = 1, FALSE = 0
  group_by(Country) |>
  summarize(num_gdp_missing = sum(gdp_missing))
```

## Final Notes

### "Pipe"

### To Create a New Object or Not

### Style
